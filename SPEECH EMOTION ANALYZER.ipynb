{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir(R'C:\\Users\\kesar\\OneDrive\\Desktop\\6th SEMESTER\\DEEP LEARNING\\PROJECT\\Ravdees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(r'C:\\Users\\kesar\\Downloads\\Audio_Song_Actors_01-24\\Actor_01\\03-02-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2356b8c7640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    male_calm\n",
       "1  female_calm\n",
       "2    male_calm\n",
       "3  female_calm\n",
       "4    male_calm\n",
       "5  female_calm\n",
       "6    male_calm\n",
       "7  female_calm\n",
       "8    male_calm\n",
       "9  female_calm"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('C:/Users/kesar/OneDrive/Desktop/6th SEMESTER/DEEP LEARNING/PROJECT/Ravdees/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-70.26777, -70.26777, -70.26777, -70.26777, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-65.70765, -65.70765, -63.11472, -61.518997, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-65.4825, -65.4825, -65.4825, -65.4825, -65.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-64.52845, -64.52845, -64.52845, -64.52845, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-62.36431, -59.934727, -61.869602, -67.49577,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-70.26777, -70.26777, -70.26777, -70.26777, -...\n",
       "1  [-65.70765, -65.70765, -63.11472, -61.518997, ...\n",
       "2  [-65.4825, -65.4825, -65.4825, -65.4825, -65.4...\n",
       "3  [-64.52845, -64.52845, -64.52845, -64.52845, -...\n",
       "4  [-62.36431, -59.934727, -61.869602, -67.49577,..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.447464</td>\n",
       "      <td>-58.896500</td>\n",
       "      <td>-58.750996</td>\n",
       "      <td>-57.405678</td>\n",
       "      <td>-60.078484</td>\n",
       "      <td>-63.426800</td>\n",
       "      <td>-62.638542</td>\n",
       "      <td>-61.082741</td>\n",
       "      <td>-60.234661</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.707649</td>\n",
       "      <td>-65.707649</td>\n",
       "      <td>-63.114719</td>\n",
       "      <td>-61.518997</td>\n",
       "      <td>-61.097141</td>\n",
       "      <td>-63.424599</td>\n",
       "      <td>-63.720066</td>\n",
       "      <td>-56.854614</td>\n",
       "      <td>-55.168972</td>\n",
       "      <td>-54.639999</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.792141</td>\n",
       "      <td>-40.613159</td>\n",
       "      <td>-41.209202</td>\n",
       "      <td>-41.439201</td>\n",
       "      <td>-43.994286</td>\n",
       "      <td>-49.399620</td>\n",
       "      <td>-50.591599</td>\n",
       "      <td>-49.144051</td>\n",
       "      <td>-48.705654</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>-65.482498</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.346556</td>\n",
       "      <td>-34.310772</td>\n",
       "      <td>-35.800705</td>\n",
       "      <td>-35.936115</td>\n",
       "      <td>-37.631844</td>\n",
       "      <td>-40.119411</td>\n",
       "      <td>-41.662888</td>\n",
       "      <td>-41.323643</td>\n",
       "      <td>-40.710770</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-64.528450</td>\n",
       "      <td>-65.928223</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.674301</td>\n",
       "      <td>-48.596073</td>\n",
       "      <td>-47.602745</td>\n",
       "      <td>-43.049198</td>\n",
       "      <td>-42.659542</td>\n",
       "      <td>-43.188560</td>\n",
       "      <td>-44.001240</td>\n",
       "      <td>-43.610100</td>\n",
       "      <td>-44.698246</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-62.364311</td>\n",
       "      <td>-59.934727</td>\n",
       "      <td>-61.869602</td>\n",
       "      <td>-67.495773</td>\n",
       "      <td>-71.071808</td>\n",
       "      <td>-65.679817</td>\n",
       "      <td>-63.394402</td>\n",
       "      <td>-65.503349</td>\n",
       "      <td>-61.856644</td>\n",
       "      <td>-60.005428</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.071327</td>\n",
       "      <td>-41.897121</td>\n",
       "      <td>-40.865437</td>\n",
       "      <td>-38.290604</td>\n",
       "      <td>-36.372398</td>\n",
       "      <td>-37.915779</td>\n",
       "      <td>-40.026127</td>\n",
       "      <td>-43.383774</td>\n",
       "      <td>-43.965401</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -70.267769 -70.267769 -70.267769 -70.267769 -70.267769 -70.267769   \n",
       "1 -65.707649 -65.707649 -63.114719 -61.518997 -61.097141 -63.424599   \n",
       "2 -65.482498 -65.482498 -65.482498 -65.482498 -65.482498 -65.482498   \n",
       "3 -64.528450 -64.528450 -64.528450 -64.528450 -64.528450 -64.528450   \n",
       "4 -62.364311 -59.934727 -61.869602 -67.495773 -71.071808 -65.679817   \n",
       "\n",
       "         6          7          8          9    ...        207        208  \\\n",
       "0 -70.267769 -70.267769 -70.267769 -70.267769  ... -57.447464 -58.896500   \n",
       "1 -63.720066 -56.854614 -55.168972 -54.639999  ... -39.792141 -40.613159   \n",
       "2 -65.482498 -65.482498 -65.482498 -65.482498  ... -31.346556 -34.310772   \n",
       "3 -64.528450 -64.528450 -64.528450 -65.928223  ... -48.674301 -48.596073   \n",
       "4 -63.394402 -65.503349 -61.856644 -60.005428  ... -39.071327 -41.897121   \n",
       "\n",
       "         209        210        211        212        213        214  \\\n",
       "0 -58.750996 -57.405678 -60.078484 -63.426800 -62.638542 -61.082741   \n",
       "1 -41.209202 -41.439201 -43.994286 -49.399620 -50.591599 -49.144051   \n",
       "2 -35.800705 -35.936115 -37.631844 -40.119411 -41.662888 -41.323643   \n",
       "3 -47.602745 -43.049198 -42.659542 -43.188560 -44.001240 -43.610100   \n",
       "4 -40.865437 -38.290604 -36.372398 -37.915779 -40.026127 -43.383774   \n",
       "\n",
       "         215          0    \n",
       "0 -60.234661    male_calm  \n",
       "1 -48.705654  female_calm  \n",
       "2 -40.710770    male_calm  \n",
       "3 -44.698246  female_calm  \n",
       "4 -43.965401    male_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-54.541561</td>\n",
       "      <td>-52.652214</td>\n",
       "      <td>-52.555290</td>\n",
       "      <td>-53.107361</td>\n",
       "      <td>-53.001789</td>\n",
       "      <td>-52.325142</td>\n",
       "      <td>-51.463894</td>\n",
       "      <td>-53.362495</td>\n",
       "      <td>-53.288208</td>\n",
       "      <td>-54.680244</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.983257</td>\n",
       "      <td>-55.473412</td>\n",
       "      <td>-54.866707</td>\n",
       "      <td>-58.022640</td>\n",
       "      <td>-57.014259</td>\n",
       "      <td>-52.991421</td>\n",
       "      <td>-52.545437</td>\n",
       "      <td>-53.893307</td>\n",
       "      <td>-55.545368</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.376183</td>\n",
       "      <td>-65.081703</td>\n",
       "      <td>-61.741520</td>\n",
       "      <td>-61.251682</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.053535</td>\n",
       "      <td>-36.484768</td>\n",
       "      <td>-36.410343</td>\n",
       "      <td>-35.979633</td>\n",
       "      <td>-36.072109</td>\n",
       "      <td>-36.145523</td>\n",
       "      <td>-36.861732</td>\n",
       "      <td>-31.365255</td>\n",
       "      <td>-27.897572</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.535198</td>\n",
       "      <td>-58.431622</td>\n",
       "      <td>-57.747078</td>\n",
       "      <td>-57.535255</td>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.398277</td>\n",
       "      <td>-58.344955</td>\n",
       "      <td>-58.380264</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.481239</td>\n",
       "      <td>-45.848122</td>\n",
       "      <td>-48.013794</td>\n",
       "      <td>-46.745735</td>\n",
       "      <td>-46.297085</td>\n",
       "      <td>-48.637230</td>\n",
       "      <td>-49.142128</td>\n",
       "      <td>-47.933006</td>\n",
       "      <td>-48.412834</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-64.875465</td>\n",
       "      <td>-56.527523</td>\n",
       "      <td>-54.121284</td>\n",
       "      <td>-55.752113</td>\n",
       "      <td>-56.003075</td>\n",
       "      <td>-55.568741</td>\n",
       "      <td>-55.626640</td>\n",
       "      <td>-56.577690</td>\n",
       "      <td>-55.229820</td>\n",
       "      <td>-55.994156</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.745186</td>\n",
       "      <td>-48.936172</td>\n",
       "      <td>-49.602459</td>\n",
       "      <td>-51.278950</td>\n",
       "      <td>-55.084087</td>\n",
       "      <td>-57.043373</td>\n",
       "      <td>-56.340080</td>\n",
       "      <td>-56.364014</td>\n",
       "      <td>-56.574608</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-60.162758</td>\n",
       "      <td>-60.162758</td>\n",
       "      <td>-60.162758</td>\n",
       "      <td>-58.697639</td>\n",
       "      <td>-59.117779</td>\n",
       "      <td>-59.412739</td>\n",
       "      <td>-59.935528</td>\n",
       "      <td>-60.093319</td>\n",
       "      <td>-59.892723</td>\n",
       "      <td>-59.975914</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.452293</td>\n",
       "      <td>-31.879854</td>\n",
       "      <td>-32.237930</td>\n",
       "      <td>-32.714520</td>\n",
       "      <td>-35.066200</td>\n",
       "      <td>-37.909229</td>\n",
       "      <td>-39.740765</td>\n",
       "      <td>-40.632664</td>\n",
       "      <td>-39.565922</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.036102</td>\n",
       "      <td>-64.665848</td>\n",
       "      <td>-62.797356</td>\n",
       "      <td>-65.690765</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>-45.079411</td>\n",
       "      <td>-45.182930</td>\n",
       "      <td>-45.832737</td>\n",
       "      <td>-45.270958</td>\n",
       "      <td>-44.004986</td>\n",
       "      <td>-43.305984</td>\n",
       "      <td>-43.619041</td>\n",
       "      <td>-44.168438</td>\n",
       "      <td>-45.227715</td>\n",
       "      <td>-46.027554</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.175652</td>\n",
       "      <td>-34.334332</td>\n",
       "      <td>-35.172134</td>\n",
       "      <td>-36.398491</td>\n",
       "      <td>-33.733013</td>\n",
       "      <td>-32.789333</td>\n",
       "      <td>-31.659161</td>\n",
       "      <td>-24.270390</td>\n",
       "      <td>-19.262936</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>-40.588501</td>\n",
       "      <td>-40.581081</td>\n",
       "      <td>-40.605572</td>\n",
       "      <td>-40.649174</td>\n",
       "      <td>-40.645645</td>\n",
       "      <td>-40.654911</td>\n",
       "      <td>-40.655983</td>\n",
       "      <td>-40.645634</td>\n",
       "      <td>-40.632099</td>\n",
       "      <td>-40.652573</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.957699</td>\n",
       "      <td>-37.451443</td>\n",
       "      <td>-39.119522</td>\n",
       "      <td>-39.735294</td>\n",
       "      <td>-40.298767</td>\n",
       "      <td>-40.656857</td>\n",
       "      <td>-40.656857</td>\n",
       "      <td>-40.656857</td>\n",
       "      <td>-40.656857</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.096539</td>\n",
       "      <td>-54.628349</td>\n",
       "      <td>-61.964287</td>\n",
       "      <td>-61.394615</td>\n",
       "      <td>-57.863480</td>\n",
       "      <td>-54.479099</td>\n",
       "      <td>-57.676800</td>\n",
       "      <td>-60.145386</td>\n",
       "      <td>-63.907143</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-60.877060</td>\n",
       "      <td>-60.643517</td>\n",
       "      <td>-62.531578</td>\n",
       "      <td>-65.584305</td>\n",
       "      <td>-65.793449</td>\n",
       "      <td>-65.793449</td>\n",
       "      <td>-65.793449</td>\n",
       "      <td>-65.793449</td>\n",
       "      <td>-65.793449</td>\n",
       "      <td>-63.589069</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.550606</td>\n",
       "      <td>-27.640730</td>\n",
       "      <td>-28.515852</td>\n",
       "      <td>-29.205854</td>\n",
       "      <td>-30.009361</td>\n",
       "      <td>-30.119699</td>\n",
       "      <td>-33.493782</td>\n",
       "      <td>-36.200535</td>\n",
       "      <td>-38.832481</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "415 -54.541561 -52.652214 -52.555290 -53.107361 -53.001789 -52.325142   \n",
       "107 -67.372910 -67.372910 -67.372910 -67.372910 -67.372910 -67.372910   \n",
       "818 -58.422295 -58.422295 -58.535198 -58.431622 -57.747078 -57.535255   \n",
       "34  -64.875465 -56.527523 -54.121284 -55.752113 -56.003075 -55.568741   \n",
       "659 -60.162758 -60.162758 -60.162758 -58.697639 -59.117779 -59.412739   \n",
       "185 -66.227669 -66.227669 -66.227669 -66.227669 -66.227669 -66.227669   \n",
       "954 -45.079411 -45.182930 -45.832737 -45.270958 -44.004986 -43.305984   \n",
       "305 -40.588501 -40.581081 -40.605572 -40.649174 -40.645645 -40.654911   \n",
       "15  -68.325424 -68.325424 -68.325424 -68.325424 -68.325424 -68.325424   \n",
       "22  -60.877060 -60.643517 -62.531578 -65.584305 -65.793449 -65.793449   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "415 -51.463894 -53.362495 -53.288208 -54.680244  ... -54.983257 -55.473412   \n",
       "107 -67.376183 -65.081703 -61.741520 -61.251682  ... -39.053535 -36.484768   \n",
       "818 -58.422295 -58.398277 -58.344955 -58.380264  ... -46.481239 -45.848122   \n",
       "34  -55.626640 -56.577690 -55.229820 -55.994156  ... -48.745186 -48.936172   \n",
       "659 -59.935528 -60.093319 -59.892723 -59.975914  ... -30.452293 -31.879854   \n",
       "185 -66.227669 -66.227669 -66.227669 -66.227669  ... -66.036102 -64.665848   \n",
       "954 -43.619041 -44.168438 -45.227715 -46.027554  ... -34.175652 -34.334332   \n",
       "305 -40.655983 -40.645634 -40.632099 -40.652573  ... -37.957699 -37.451443   \n",
       "15  -68.325424 -68.325424 -68.325424 -68.325424  ... -52.096539 -54.628349   \n",
       "22  -65.793449 -65.793449 -65.793449 -63.589069  ... -27.550606 -27.640730   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "415 -54.866707 -58.022640 -57.014259 -52.991421 -52.545437 -53.893307   \n",
       "107 -36.410343 -35.979633 -36.072109 -36.145523 -36.861732 -31.365255   \n",
       "818 -48.013794 -46.745735 -46.297085 -48.637230 -49.142128 -47.933006   \n",
       "34  -49.602459 -51.278950 -55.084087 -57.043373 -56.340080 -56.364014   \n",
       "659 -32.237930 -32.714520 -35.066200 -37.909229 -39.740765 -40.632664   \n",
       "185 -62.797356 -65.690765 -66.227669 -66.227669 -66.227669 -66.227669   \n",
       "954 -35.172134 -36.398491 -33.733013 -32.789333 -31.659161 -24.270390   \n",
       "305 -39.119522 -39.735294 -40.298767 -40.656857 -40.656857 -40.656857   \n",
       "15  -61.964287 -61.394615 -57.863480 -54.479099 -57.676800 -60.145386   \n",
       "22  -28.515852 -29.205854 -30.009361 -30.119699 -33.493782 -36.200535   \n",
       "\n",
       "           215           0    \n",
       "415 -55.545368    female_sad  \n",
       "107 -27.897572   female_calm  \n",
       "818 -48.412834  male_fearful  \n",
       "34  -56.574608     male_calm  \n",
       "659 -39.565922  female_angry  \n",
       "185 -66.227669   female_calm  \n",
       "954 -19.262936  male_fearful  \n",
       "305 -40.656857  female_happy  \n",
       "15  -63.907143   female_calm  \n",
       "22  -38.832481     male_calm  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.372910</td>\n",
       "      <td>-67.376183</td>\n",
       "      <td>-65.081703</td>\n",
       "      <td>-61.741520</td>\n",
       "      <td>-61.251682</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.053535</td>\n",
       "      <td>-36.484768</td>\n",
       "      <td>-36.410343</td>\n",
       "      <td>-35.979633</td>\n",
       "      <td>-36.072109</td>\n",
       "      <td>-36.145523</td>\n",
       "      <td>-36.861732</td>\n",
       "      <td>-31.365255</td>\n",
       "      <td>-27.897572</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.535198</td>\n",
       "      <td>-58.431622</td>\n",
       "      <td>-57.747078</td>\n",
       "      <td>-57.535255</td>\n",
       "      <td>-58.422295</td>\n",
       "      <td>-58.398277</td>\n",
       "      <td>-58.344955</td>\n",
       "      <td>-58.380264</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.481239</td>\n",
       "      <td>-45.848122</td>\n",
       "      <td>-48.013794</td>\n",
       "      <td>-46.745735</td>\n",
       "      <td>-46.297085</td>\n",
       "      <td>-48.637230</td>\n",
       "      <td>-49.142128</td>\n",
       "      <td>-47.933006</td>\n",
       "      <td>-48.412834</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.036102</td>\n",
       "      <td>-64.665848</td>\n",
       "      <td>-62.797356</td>\n",
       "      <td>-65.690765</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>-66.227669</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>-45.079411</td>\n",
       "      <td>-45.182930</td>\n",
       "      <td>-45.832737</td>\n",
       "      <td>-45.270958</td>\n",
       "      <td>-44.004986</td>\n",
       "      <td>-43.305984</td>\n",
       "      <td>-43.619041</td>\n",
       "      <td>-44.168438</td>\n",
       "      <td>-45.227715</td>\n",
       "      <td>-46.027554</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.175652</td>\n",
       "      <td>-34.334332</td>\n",
       "      <td>-35.172134</td>\n",
       "      <td>-36.398491</td>\n",
       "      <td>-33.733013</td>\n",
       "      <td>-32.789333</td>\n",
       "      <td>-31.659161</td>\n",
       "      <td>-24.270390</td>\n",
       "      <td>-19.262936</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.096539</td>\n",
       "      <td>-54.628349</td>\n",
       "      <td>-61.964287</td>\n",
       "      <td>-61.394615</td>\n",
       "      <td>-57.863480</td>\n",
       "      <td>-54.479099</td>\n",
       "      <td>-57.676800</td>\n",
       "      <td>-60.145386</td>\n",
       "      <td>-63.907143</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "107 -67.372910 -67.372910 -67.372910 -67.372910 -67.372910 -67.372910   \n",
       "818 -58.422295 -58.422295 -58.535198 -58.431622 -57.747078 -57.535255   \n",
       "185 -66.227669 -66.227669 -66.227669 -66.227669 -66.227669 -66.227669   \n",
       "954 -45.079411 -45.182930 -45.832737 -45.270958 -44.004986 -43.305984   \n",
       "15  -68.325424 -68.325424 -68.325424 -68.325424 -68.325424 -68.325424   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "107 -67.376183 -65.081703 -61.741520 -61.251682  ... -39.053535 -36.484768   \n",
       "818 -58.422295 -58.398277 -58.344955 -58.380264  ... -46.481239 -45.848122   \n",
       "185 -66.227669 -66.227669 -66.227669 -66.227669  ... -66.036102 -64.665848   \n",
       "954 -43.619041 -44.168438 -45.227715 -46.027554  ... -34.175652 -34.334332   \n",
       "15  -68.325424 -68.325424 -68.325424 -68.325424  ... -52.096539 -54.628349   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "107 -36.410343 -35.979633 -36.072109 -36.145523 -36.861732 -31.365255   \n",
       "818 -48.013794 -46.745735 -46.297085 -48.637230 -49.142128 -47.933006   \n",
       "185 -62.797356 -65.690765 -66.227669 -66.227669 -66.227669 -66.227669   \n",
       "954 -35.172134 -36.398491 -33.733013 -32.789333 -31.659161 -24.270390   \n",
       "15  -61.964287 -61.394615 -57.863480 -54.479099 -57.676800 -60.145386   \n",
       "\n",
       "           215           0    \n",
       "107 -27.897572   female_calm  \n",
       "818 -48.412834  male_fearful  \n",
       "185 -66.227669   female_calm  \n",
       "954 -19.262936  male_fearful  \n",
       "15  -63.907143   female_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesar\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 216)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 2.4407 - accuracy: 0.1007 - val_loss: 2.2979 - val_accuracy: 0.0974\n",
      "Epoch 2/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 2.2742 - accuracy: 0.1412 - val_loss: 2.2479 - val_accuracy: 0.1538\n",
      "Epoch 3/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.2436 - accuracy: 0.1765 - val_loss: 2.2188 - val_accuracy: 0.1436\n",
      "Epoch 4/500\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 2.2224 - accuracy: 0.1935 - val_loss: 2.2035 - val_accuracy: 0.1949\n",
      "Epoch 5/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.2016 - accuracy: 0.1961 - val_loss: 2.2000 - val_accuracy: 0.1897\n",
      "Epoch 6/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.1817 - accuracy: 0.2092 - val_loss: 2.1708 - val_accuracy: 0.2359\n",
      "Epoch 7/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 2.1661 - accuracy: 0.2118 - val_loss: 2.1690 - val_accuracy: 0.2103\n",
      "Epoch 8/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 2.1500 - accuracy: 0.2235 - val_loss: 2.1577 - val_accuracy: 0.2051\n",
      "Epoch 9/500\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 2.1354 - accuracy: 0.2235 - val_loss: 2.1326 - val_accuracy: 0.2462\n",
      "Epoch 10/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 2.1147 - accuracy: 0.2353 - val_loss: 2.1063 - val_accuracy: 0.2974\n",
      "Epoch 11/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.1037 - accuracy: 0.2392 - val_loss: 2.0996 - val_accuracy: 0.3026\n",
      "Epoch 12/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.0817 - accuracy: 0.2601 - val_loss: 2.0897 - val_accuracy: 0.3385\n",
      "Epoch 13/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.0644 - accuracy: 0.2863 - val_loss: 2.1094 - val_accuracy: 0.2154\n",
      "Epoch 14/500\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 2.0490 - accuracy: 0.2771 - val_loss: 2.0485 - val_accuracy: 0.3231\n",
      "Epoch 15/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 2.0411 - accuracy: 0.2654 - val_loss: 2.0279 - val_accuracy: 0.3385\n",
      "Epoch 16/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 2.0191 - accuracy: 0.2771 - val_loss: 2.0332 - val_accuracy: 0.2718\n",
      "Epoch 17/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 2.0073 - accuracy: 0.2889 - val_loss: 2.0150 - val_accuracy: 0.2667\n",
      "Epoch 18/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.9830 - accuracy: 0.3320 - val_loss: 2.0079 - val_accuracy: 0.2462\n",
      "Epoch 19/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.9699 - accuracy: 0.3059 - val_loss: 1.9780 - val_accuracy: 0.3231\n",
      "Epoch 20/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.9573 - accuracy: 0.3190 - val_loss: 1.9568 - val_accuracy: 0.3179\n",
      "Epoch 21/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.9406 - accuracy: 0.3216 - val_loss: 1.9493 - val_accuracy: 0.3692\n",
      "Epoch 22/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 1.9264 - accuracy: 0.3346 - val_loss: 1.9372 - val_accuracy: 0.3282\n",
      "Epoch 23/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.9122 - accuracy: 0.3542 - val_loss: 1.9261 - val_accuracy: 0.3385\n",
      "Epoch 24/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.9014 - accuracy: 0.3412 - val_loss: 1.9042 - val_accuracy: 0.3795\n",
      "Epoch 25/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.8819 - accuracy: 0.3477 - val_loss: 1.9105 - val_accuracy: 0.3282\n",
      "Epoch 26/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.8753 - accuracy: 0.3634 - val_loss: 1.8873 - val_accuracy: 0.3795\n",
      "Epoch 27/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.8605 - accuracy: 0.3477 - val_loss: 1.8688 - val_accuracy: 0.3692\n",
      "Epoch 28/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.8402 - accuracy: 0.3686 - val_loss: 1.8831 - val_accuracy: 0.3385\n",
      "Epoch 29/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.8250 - accuracy: 0.3647 - val_loss: 1.8375 - val_accuracy: 0.3538\n",
      "Epoch 30/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.8262 - accuracy: 0.3673 - val_loss: 1.8369 - val_accuracy: 0.3487\n",
      "Epoch 31/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.8124 - accuracy: 0.3621 - val_loss: 1.8261 - val_accuracy: 0.3282\n",
      "Epoch 32/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.8008 - accuracy: 0.3765 - val_loss: 1.8244 - val_accuracy: 0.3282\n",
      "Epoch 33/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.7837 - accuracy: 0.3765 - val_loss: 1.8189 - val_accuracy: 0.3487\n",
      "Epoch 34/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 1.7756 - accuracy: 0.3725 - val_loss: 1.7870 - val_accuracy: 0.3897\n",
      "Epoch 35/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.7661 - accuracy: 0.3712 - val_loss: 1.7680 - val_accuracy: 0.3641\n",
      "Epoch 36/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.7549 - accuracy: 0.3856 - val_loss: 1.7952 - val_accuracy: 0.3692\n",
      "Epoch 37/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 1.7465 - accuracy: 0.3974 - val_loss: 1.7672 - val_accuracy: 0.3744\n",
      "Epoch 38/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.7427 - accuracy: 0.3948 - val_loss: 1.7531 - val_accuracy: 0.3590\n",
      "Epoch 39/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 1.7247 - accuracy: 0.3935 - val_loss: 1.7370 - val_accuracy: 0.4000\n",
      "Epoch 40/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.7162 - accuracy: 0.3987 - val_loss: 1.7360 - val_accuracy: 0.3641\n",
      "Epoch 41/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.7099 - accuracy: 0.4000 - val_loss: 1.7482 - val_accuracy: 0.3538\n",
      "Epoch 42/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.6930 - accuracy: 0.4092 - val_loss: 1.7347 - val_accuracy: 0.3641\n",
      "Epoch 43/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.6907 - accuracy: 0.3948 - val_loss: 1.7089 - val_accuracy: 0.3692\n",
      "Epoch 44/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.6798 - accuracy: 0.4052 - val_loss: 1.7062 - val_accuracy: 0.3795\n",
      "Epoch 45/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.6720 - accuracy: 0.4118 - val_loss: 1.7256 - val_accuracy: 0.3231\n",
      "Epoch 46/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.6581 - accuracy: 0.4118 - val_loss: 1.6812 - val_accuracy: 0.3897\n",
      "Epoch 47/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.6529 - accuracy: 0.4078 - val_loss: 1.6786 - val_accuracy: 0.3641\n",
      "Epoch 48/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.6414 - accuracy: 0.4248 - val_loss: 1.6651 - val_accuracy: 0.4051\n",
      "Epoch 49/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.6259 - accuracy: 0.4275 - val_loss: 1.7138 - val_accuracy: 0.3487\n",
      "Epoch 50/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.6261 - accuracy: 0.4235 - val_loss: 1.6574 - val_accuracy: 0.4000\n",
      "Epoch 51/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.6151 - accuracy: 0.4275 - val_loss: 1.6733 - val_accuracy: 0.3590\n",
      "Epoch 52/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.6048 - accuracy: 0.4261 - val_loss: 1.6388 - val_accuracy: 0.3744\n",
      "Epoch 53/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.5992 - accuracy: 0.4183 - val_loss: 1.6764 - val_accuracy: 0.3744\n",
      "Epoch 54/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.5888 - accuracy: 0.4248 - val_loss: 1.6500 - val_accuracy: 0.4103\n",
      "Epoch 55/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.5822 - accuracy: 0.4366 - val_loss: 1.6009 - val_accuracy: 0.4359\n",
      "Epoch 56/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.5755 - accuracy: 0.4366 - val_loss: 1.6177 - val_accuracy: 0.4256\n",
      "Epoch 57/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.5734 - accuracy: 0.4549 - val_loss: 1.5894 - val_accuracy: 0.4308\n",
      "Epoch 58/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.5635 - accuracy: 0.4327 - val_loss: 1.5976 - val_accuracy: 0.4205\n",
      "Epoch 59/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.5470 - accuracy: 0.4458 - val_loss: 1.6065 - val_accuracy: 0.3744\n",
      "Epoch 60/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.5421 - accuracy: 0.4458 - val_loss: 1.6254 - val_accuracy: 0.3641\n",
      "Epoch 61/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.5352 - accuracy: 0.4497 - val_loss: 1.5986 - val_accuracy: 0.4359\n",
      "Epoch 62/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.5318 - accuracy: 0.4444 - val_loss: 1.5825 - val_accuracy: 0.4359\n",
      "Epoch 63/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.5173 - accuracy: 0.4340 - val_loss: 1.5631 - val_accuracy: 0.3744\n",
      "Epoch 64/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.5200 - accuracy: 0.4549 - val_loss: 1.5717 - val_accuracy: 0.3897\n",
      "Epoch 65/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.5085 - accuracy: 0.4549 - val_loss: 1.5421 - val_accuracy: 0.4000\n",
      "Epoch 66/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.4912 - accuracy: 0.4693 - val_loss: 1.5750 - val_accuracy: 0.3949\n",
      "Epoch 67/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.4980 - accuracy: 0.4667 - val_loss: 1.5689 - val_accuracy: 0.4051\n",
      "Epoch 68/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.4927 - accuracy: 0.4641 - val_loss: 1.5484 - val_accuracy: 0.4000\n",
      "Epoch 69/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4892 - accuracy: 0.4458 - val_loss: 1.5414 - val_accuracy: 0.3846\n",
      "Epoch 70/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.4726 - accuracy: 0.4706 - val_loss: 1.5386 - val_accuracy: 0.4410\n",
      "Epoch 71/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.4662 - accuracy: 0.4693 - val_loss: 1.5762 - val_accuracy: 0.4051\n",
      "Epoch 72/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4640 - accuracy: 0.4758 - val_loss: 1.5017 - val_accuracy: 0.4308\n",
      "Epoch 73/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.4623 - accuracy: 0.4667 - val_loss: 1.5197 - val_accuracy: 0.4154\n",
      "Epoch 74/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.4535 - accuracy: 0.4562 - val_loss: 1.5418 - val_accuracy: 0.4051\n",
      "Epoch 75/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4571 - accuracy: 0.4379 - val_loss: 1.5303 - val_accuracy: 0.4462\n",
      "Epoch 76/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.4477 - accuracy: 0.4706 - val_loss: 1.5001 - val_accuracy: 0.4154\n",
      "Epoch 77/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.4339 - accuracy: 0.4837 - val_loss: 1.5423 - val_accuracy: 0.4051\n",
      "Epoch 78/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.4342 - accuracy: 0.4719 - val_loss: 1.4837 - val_accuracy: 0.4615\n",
      "Epoch 79/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4278 - accuracy: 0.4732 - val_loss: 1.5164 - val_accuracy: 0.3949\n",
      "Epoch 80/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4198 - accuracy: 0.4902 - val_loss: 1.5012 - val_accuracy: 0.4308\n",
      "Epoch 81/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.4185 - accuracy: 0.4680 - val_loss: 1.4736 - val_accuracy: 0.4462\n",
      "Epoch 82/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.4164 - accuracy: 0.4784 - val_loss: 1.5396 - val_accuracy: 0.4051\n",
      "Epoch 83/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.4077 - accuracy: 0.4810 - val_loss: 1.5071 - val_accuracy: 0.4154\n",
      "Epoch 84/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.4138 - accuracy: 0.4824 - val_loss: 1.5577 - val_accuracy: 0.3949\n",
      "Epoch 85/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4084 - accuracy: 0.4797 - val_loss: 1.4772 - val_accuracy: 0.4103\n",
      "Epoch 86/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.4071 - accuracy: 0.4706 - val_loss: 1.4754 - val_accuracy: 0.4667\n",
      "Epoch 87/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.3928 - accuracy: 0.4954 - val_loss: 1.4566 - val_accuracy: 0.4615\n",
      "Epoch 88/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3918 - accuracy: 0.4915 - val_loss: 1.4627 - val_accuracy: 0.4205\n",
      "Epoch 89/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.3860 - accuracy: 0.4915 - val_loss: 1.4659 - val_accuracy: 0.4205\n",
      "Epoch 90/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.3788 - accuracy: 0.5085 - val_loss: 1.4652 - val_accuracy: 0.4256\n",
      "Epoch 91/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.3736 - accuracy: 0.4810 - val_loss: 1.4382 - val_accuracy: 0.4308\n",
      "Epoch 92/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.3672 - accuracy: 0.5098 - val_loss: 1.4785 - val_accuracy: 0.4154\n",
      "Epoch 93/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3706 - accuracy: 0.4928 - val_loss: 1.4967 - val_accuracy: 0.4462\n",
      "Epoch 94/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3695 - accuracy: 0.4876 - val_loss: 1.4656 - val_accuracy: 0.4410\n",
      "Epoch 95/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3585 - accuracy: 0.4941 - val_loss: 1.5359 - val_accuracy: 0.4103\n",
      "Epoch 96/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.3535 - accuracy: 0.4993 - val_loss: 1.4863 - val_accuracy: 0.4513\n",
      "Epoch 97/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.3428 - accuracy: 0.5085 - val_loss: 1.4932 - val_accuracy: 0.4410\n",
      "Epoch 98/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3494 - accuracy: 0.4993 - val_loss: 1.4447 - val_accuracy: 0.3949\n",
      "Epoch 99/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.3470 - accuracy: 0.4954 - val_loss: 1.4749 - val_accuracy: 0.4513\n",
      "Epoch 100/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.3616 - accuracy: 0.4954 - val_loss: 1.4364 - val_accuracy: 0.4154\n",
      "Epoch 101/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.3413 - accuracy: 0.5137 - val_loss: 1.4545 - val_accuracy: 0.4462\n",
      "Epoch 102/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.3375 - accuracy: 0.5059 - val_loss: 1.4381 - val_accuracy: 0.4410\n",
      "Epoch 103/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3394 - accuracy: 0.5176 - val_loss: 1.4774 - val_accuracy: 0.4462\n",
      "Epoch 104/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3268 - accuracy: 0.5020 - val_loss: 1.5490 - val_accuracy: 0.4256\n",
      "Epoch 105/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.3120 - accuracy: 0.5320 - val_loss: 1.4678 - val_accuracy: 0.4410\n",
      "Epoch 106/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.3254 - accuracy: 0.4980 - val_loss: 1.4752 - val_accuracy: 0.4308\n",
      "Epoch 107/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3179 - accuracy: 0.5033 - val_loss: 1.4347 - val_accuracy: 0.4205\n",
      "Epoch 108/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.3107 - accuracy: 0.5294 - val_loss: 1.5285 - val_accuracy: 0.4205\n",
      "Epoch 109/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.3146 - accuracy: 0.5307 - val_loss: 1.4082 - val_accuracy: 0.4308\n",
      "Epoch 110/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.3183 - accuracy: 0.5163 - val_loss: 1.4126 - val_accuracy: 0.4769\n",
      "Epoch 111/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.3188 - accuracy: 0.5190 - val_loss: 1.4272 - val_accuracy: 0.4462\n",
      "Epoch 112/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 1.2974 - accuracy: 0.5294 - val_loss: 1.4966 - val_accuracy: 0.4256\n",
      "Epoch 113/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.3014 - accuracy: 0.5268 - val_loss: 1.5075 - val_accuracy: 0.4000\n",
      "Epoch 114/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.3013 - accuracy: 0.5163 - val_loss: 1.4268 - val_accuracy: 0.4308\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 3s 66ms/step - loss: 1.2937 - accuracy: 0.5190 - val_loss: 1.4569 - val_accuracy: 0.4410\n",
      "Epoch 116/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.2903 - accuracy: 0.5333 - val_loss: 1.3923 - val_accuracy: 0.4564\n",
      "Epoch 117/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.2931 - accuracy: 0.5373 - val_loss: 1.4368 - val_accuracy: 0.4256\n",
      "Epoch 118/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2811 - accuracy: 0.5425 - val_loss: 1.3983 - val_accuracy: 0.4615\n",
      "Epoch 119/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2827 - accuracy: 0.5320 - val_loss: 1.3962 - val_accuracy: 0.4667\n",
      "Epoch 120/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.2834 - accuracy: 0.5373 - val_loss: 1.4694 - val_accuracy: 0.4308\n",
      "Epoch 121/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.2759 - accuracy: 0.5307 - val_loss: 1.6296 - val_accuracy: 0.3897\n",
      "Epoch 122/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2784 - accuracy: 0.5203 - val_loss: 1.4470 - val_accuracy: 0.4462\n",
      "Epoch 123/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2776 - accuracy: 0.5333 - val_loss: 1.4180 - val_accuracy: 0.4154\n",
      "Epoch 124/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2756 - accuracy: 0.5268 - val_loss: 1.4505 - val_accuracy: 0.4308\n",
      "Epoch 125/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 1.2679 - accuracy: 0.5307 - val_loss: 1.4056 - val_accuracy: 0.4513\n",
      "Epoch 126/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2556 - accuracy: 0.5281 - val_loss: 1.4375 - val_accuracy: 0.4308\n",
      "Epoch 127/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2618 - accuracy: 0.5346 - val_loss: 1.4068 - val_accuracy: 0.4308\n",
      "Epoch 128/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2565 - accuracy: 0.5451 - val_loss: 1.3981 - val_accuracy: 0.4462\n",
      "Epoch 129/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.2520 - accuracy: 0.5464 - val_loss: 1.4087 - val_accuracy: 0.4564\n",
      "Epoch 130/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.2469 - accuracy: 0.5503 - val_loss: 1.4235 - val_accuracy: 0.4462\n",
      "Epoch 131/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2421 - accuracy: 0.5464 - val_loss: 1.3900 - val_accuracy: 0.4359\n",
      "Epoch 132/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2537 - accuracy: 0.5477 - val_loss: 1.3819 - val_accuracy: 0.4615\n",
      "Epoch 133/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 1.2472 - accuracy: 0.5529 - val_loss: 1.5211 - val_accuracy: 0.4154\n",
      "Epoch 134/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.2460 - accuracy: 0.5373 - val_loss: 1.3916 - val_accuracy: 0.4103\n",
      "Epoch 135/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.2443 - accuracy: 0.5386 - val_loss: 1.4183 - val_accuracy: 0.4462\n",
      "Epoch 136/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2349 - accuracy: 0.5725 - val_loss: 1.4435 - val_accuracy: 0.4615\n",
      "Epoch 137/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2395 - accuracy: 0.5294 - val_loss: 1.4065 - val_accuracy: 0.4564\n",
      "Epoch 138/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2346 - accuracy: 0.5556 - val_loss: 1.3914 - val_accuracy: 0.4667\n",
      "Epoch 139/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.2309 - accuracy: 0.5765 - val_loss: 1.3920 - val_accuracy: 0.4615\n",
      "Epoch 140/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2284 - accuracy: 0.5595 - val_loss: 1.3740 - val_accuracy: 0.4564\n",
      "Epoch 141/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2280 - accuracy: 0.5673 - val_loss: 1.4617 - val_accuracy: 0.4359\n",
      "Epoch 142/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.2173 - accuracy: 0.5621 - val_loss: 1.4063 - val_accuracy: 0.4410\n",
      "Epoch 143/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.2166 - accuracy: 0.5608 - val_loss: 1.4031 - val_accuracy: 0.4769\n",
      "Epoch 144/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.2120 - accuracy: 0.5660 - val_loss: 1.4670 - val_accuracy: 0.4308\n",
      "Epoch 145/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.2341 - accuracy: 0.5307 - val_loss: 1.4169 - val_accuracy: 0.4410\n",
      "Epoch 146/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.2095 - accuracy: 0.5608 - val_loss: 1.4100 - val_accuracy: 0.4667\n",
      "Epoch 147/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.2072 - accuracy: 0.5804 - val_loss: 1.4065 - val_accuracy: 0.4410\n",
      "Epoch 148/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.2152 - accuracy: 0.5529 - val_loss: 1.3995 - val_accuracy: 0.4359\n",
      "Epoch 149/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.2017 - accuracy: 0.5699 - val_loss: 1.3815 - val_accuracy: 0.4513\n",
      "Epoch 150/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.1962 - accuracy: 0.5542 - val_loss: 1.5412 - val_accuracy: 0.4000\n",
      "Epoch 151/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2116 - accuracy: 0.5595 - val_loss: 1.4216 - val_accuracy: 0.4205\n",
      "Epoch 152/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.1908 - accuracy: 0.5660 - val_loss: 1.5005 - val_accuracy: 0.4256\n",
      "Epoch 153/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.2064 - accuracy: 0.5752 - val_loss: 1.4206 - val_accuracy: 0.4410\n",
      "Epoch 154/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 1.2023 - accuracy: 0.5647 - val_loss: 1.4020 - val_accuracy: 0.4667\n",
      "Epoch 155/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.2011 - accuracy: 0.5712 - val_loss: 1.4286 - val_accuracy: 0.4308\n",
      "Epoch 156/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.1893 - accuracy: 0.5765 - val_loss: 1.3732 - val_accuracy: 0.4564\n",
      "Epoch 157/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.1864 - accuracy: 0.5634 - val_loss: 1.3886 - val_accuracy: 0.4615\n",
      "Epoch 158/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.1925 - accuracy: 0.5739 - val_loss: 1.3998 - val_accuracy: 0.4769\n",
      "Epoch 159/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1860 - accuracy: 0.5699 - val_loss: 1.4146 - val_accuracy: 0.4615\n",
      "Epoch 160/500\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 1.1799 - accuracy: 0.5725 - val_loss: 1.4838 - val_accuracy: 0.4154\n",
      "Epoch 161/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1836 - accuracy: 0.5686 - val_loss: 1.3673 - val_accuracy: 0.4821\n",
      "Epoch 162/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.1803 - accuracy: 0.5634 - val_loss: 1.3808 - val_accuracy: 0.4718\n",
      "Epoch 163/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1693 - accuracy: 0.5804 - val_loss: 1.3954 - val_accuracy: 0.4462\n",
      "Epoch 164/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1742 - accuracy: 0.5647 - val_loss: 1.4408 - val_accuracy: 0.4205\n",
      "Epoch 165/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1743 - accuracy: 0.5791 - val_loss: 1.3714 - val_accuracy: 0.4667\n",
      "Epoch 166/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.1675 - accuracy: 0.5843 - val_loss: 1.5264 - val_accuracy: 0.4256\n",
      "Epoch 167/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.1624 - accuracy: 0.5895 - val_loss: 1.3840 - val_accuracy: 0.4513\n",
      "Epoch 168/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1668 - accuracy: 0.5699 - val_loss: 1.4167 - val_accuracy: 0.4205\n",
      "Epoch 169/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1610 - accuracy: 0.5922 - val_loss: 1.4170 - val_accuracy: 0.4615\n",
      "Epoch 170/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1594 - accuracy: 0.5778 - val_loss: 1.3742 - val_accuracy: 0.4667\n",
      "Epoch 171/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.1625 - accuracy: 0.5895 - val_loss: 1.3570 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1513 - accuracy: 0.5804 - val_loss: 1.3667 - val_accuracy: 0.4513\n",
      "Epoch 173/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1527 - accuracy: 0.5739 - val_loss: 1.4409 - val_accuracy: 0.4462\n",
      "Epoch 174/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.1616 - accuracy: 0.5843 - val_loss: 1.3928 - val_accuracy: 0.4718\n",
      "Epoch 175/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.1452 - accuracy: 0.5791 - val_loss: 1.3589 - val_accuracy: 0.4667\n",
      "Epoch 176/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.1471 - accuracy: 0.5961 - val_loss: 1.4224 - val_accuracy: 0.4718\n",
      "Epoch 177/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1486 - accuracy: 0.5974 - val_loss: 1.3831 - val_accuracy: 0.4564\n",
      "Epoch 178/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1381 - accuracy: 0.5895 - val_loss: 1.5186 - val_accuracy: 0.4051\n",
      "Epoch 179/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1490 - accuracy: 0.5961 - val_loss: 1.4269 - val_accuracy: 0.4410\n",
      "Epoch 180/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.1411 - accuracy: 0.5974 - val_loss: 1.3685 - val_accuracy: 0.4923\n",
      "Epoch 181/500\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 1.1363 - accuracy: 0.5856 - val_loss: 1.4107 - val_accuracy: 0.4564\n",
      "Epoch 182/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1374 - accuracy: 0.5922 - val_loss: 1.4131 - val_accuracy: 0.4718\n",
      "Epoch 183/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.1359 - accuracy: 0.5908 - val_loss: 1.4289 - val_accuracy: 0.4564\n",
      "Epoch 184/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.1331 - accuracy: 0.5974 - val_loss: 1.4719 - val_accuracy: 0.4462\n",
      "Epoch 185/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.1244 - accuracy: 0.5843 - val_loss: 1.5923 - val_accuracy: 0.4051\n",
      "Epoch 186/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1325 - accuracy: 0.5908 - val_loss: 1.3988 - val_accuracy: 0.4718\n",
      "Epoch 187/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1290 - accuracy: 0.5922 - val_loss: 1.3813 - val_accuracy: 0.4718\n",
      "Epoch 188/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1214 - accuracy: 0.6026 - val_loss: 1.4304 - val_accuracy: 0.4256\n",
      "Epoch 189/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.1315 - accuracy: 0.5987 - val_loss: 1.3602 - val_accuracy: 0.4769\n",
      "Epoch 190/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1168 - accuracy: 0.6039 - val_loss: 1.3653 - val_accuracy: 0.4718\n",
      "Epoch 191/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1271 - accuracy: 0.6052 - val_loss: 1.4809 - val_accuracy: 0.4462\n",
      "Epoch 192/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1169 - accuracy: 0.6078 - val_loss: 1.3844 - val_accuracy: 0.4821\n",
      "Epoch 193/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.1068 - accuracy: 0.6026 - val_loss: 1.4416 - val_accuracy: 0.4359\n",
      "Epoch 194/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.1190 - accuracy: 0.6000 - val_loss: 1.3640 - val_accuracy: 0.4718\n",
      "Epoch 195/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.1136 - accuracy: 0.5843 - val_loss: 1.4537 - val_accuracy: 0.4308\n",
      "Epoch 196/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.1007 - accuracy: 0.5987 - val_loss: 1.3702 - val_accuracy: 0.4974\n",
      "Epoch 197/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.1031 - accuracy: 0.6052 - val_loss: 1.4688 - val_accuracy: 0.4256\n",
      "Epoch 198/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.1138 - accuracy: 0.6078 - val_loss: 1.3801 - val_accuracy: 0.4821\n",
      "Epoch 199/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 1.1042 - accuracy: 0.5974 - val_loss: 1.4100 - val_accuracy: 0.4615\n",
      "Epoch 200/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.1002 - accuracy: 0.6170 - val_loss: 1.4338 - val_accuracy: 0.4718\n",
      "Epoch 201/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0802 - accuracy: 0.6144 - val_loss: 1.4139 - val_accuracy: 0.4462\n",
      "Epoch 202/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 1.0988 - accuracy: 0.6131 - val_loss: 1.3641 - val_accuracy: 0.5026\n",
      "Epoch 203/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.1019 - accuracy: 0.6092 - val_loss: 1.3622 - val_accuracy: 0.4564\n",
      "Epoch 204/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.0880 - accuracy: 0.6065 - val_loss: 1.4003 - val_accuracy: 0.4718\n",
      "Epoch 205/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0929 - accuracy: 0.6183 - val_loss: 1.4601 - val_accuracy: 0.4359\n",
      "Epoch 206/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0882 - accuracy: 0.6105 - val_loss: 1.4826 - val_accuracy: 0.4564\n",
      "Epoch 207/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.0924 - accuracy: 0.6026 - val_loss: 1.4062 - val_accuracy: 0.4718\n",
      "Epoch 208/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0776 - accuracy: 0.6131 - val_loss: 1.5924 - val_accuracy: 0.4000\n",
      "Epoch 209/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0895 - accuracy: 0.6065 - val_loss: 1.3605 - val_accuracy: 0.4564\n",
      "Epoch 210/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0777 - accuracy: 0.6209 - val_loss: 1.3539 - val_accuracy: 0.4923\n",
      "Epoch 211/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0868 - accuracy: 0.6105 - val_loss: 1.4920 - val_accuracy: 0.4667\n",
      "Epoch 212/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.0825 - accuracy: 0.6144 - val_loss: 1.3801 - val_accuracy: 0.4821\n",
      "Epoch 213/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0784 - accuracy: 0.6092 - val_loss: 1.3485 - val_accuracy: 0.4821\n",
      "Epoch 214/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0830 - accuracy: 0.6261 - val_loss: 1.3930 - val_accuracy: 0.4769\n",
      "Epoch 215/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0776 - accuracy: 0.6157 - val_loss: 1.4260 - val_accuracy: 0.4513\n",
      "Epoch 216/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.0672 - accuracy: 0.6026 - val_loss: 1.3999 - val_accuracy: 0.4513\n",
      "Epoch 217/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0710 - accuracy: 0.6131 - val_loss: 1.4362 - val_accuracy: 0.4769\n",
      "Epoch 218/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0763 - accuracy: 0.6144 - val_loss: 1.4191 - val_accuracy: 0.4462\n",
      "Epoch 219/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0737 - accuracy: 0.6144 - val_loss: 1.4760 - val_accuracy: 0.4205\n",
      "Epoch 220/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0637 - accuracy: 0.6275 - val_loss: 1.3807 - val_accuracy: 0.4615\n",
      "Epoch 221/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.0612 - accuracy: 0.6444 - val_loss: 1.3598 - val_accuracy: 0.4923\n",
      "Epoch 222/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0644 - accuracy: 0.6183 - val_loss: 1.3803 - val_accuracy: 0.5231\n",
      "Epoch 223/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0619 - accuracy: 0.6170 - val_loss: 1.3768 - val_accuracy: 0.4667\n",
      "Epoch 224/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.0606 - accuracy: 0.6235 - val_loss: 1.3904 - val_accuracy: 0.4769\n",
      "Epoch 225/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.0590 - accuracy: 0.6222 - val_loss: 1.3873 - val_accuracy: 0.4564\n",
      "Epoch 226/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0595 - accuracy: 0.6248 - val_loss: 1.3746 - val_accuracy: 0.5026\n",
      "Epoch 227/500\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 1.0612 - accuracy: 0.6183 - val_loss: 1.3788 - val_accuracy: 0.4718\n",
      "Epoch 228/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0497 - accuracy: 0.6288 - val_loss: 1.3668 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 1.0587 - accuracy: 0.6327 - val_loss: 1.3971 - val_accuracy: 0.4615\n",
      "Epoch 230/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.0528 - accuracy: 0.6222 - val_loss: 1.4418 - val_accuracy: 0.4462\n",
      "Epoch 231/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.0593 - accuracy: 0.6183 - val_loss: 1.3711 - val_accuracy: 0.4718\n",
      "Epoch 232/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.0518 - accuracy: 0.6340 - val_loss: 1.4346 - val_accuracy: 0.4410\n",
      "Epoch 233/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 1.0439 - accuracy: 0.6379 - val_loss: 1.3991 - val_accuracy: 0.4615\n",
      "Epoch 234/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.0414 - accuracy: 0.6458 - val_loss: 1.3539 - val_accuracy: 0.4974\n",
      "Epoch 235/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.0393 - accuracy: 0.6275 - val_loss: 1.4750 - val_accuracy: 0.4513\n",
      "Epoch 236/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0508 - accuracy: 0.6405 - val_loss: 1.4307 - val_accuracy: 0.4462\n",
      "Epoch 237/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0437 - accuracy: 0.6275 - val_loss: 1.3962 - val_accuracy: 0.4769\n",
      "Epoch 238/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0418 - accuracy: 0.6301 - val_loss: 1.3937 - val_accuracy: 0.4821\n",
      "Epoch 239/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 1.0305 - accuracy: 0.6144 - val_loss: 1.4086 - val_accuracy: 0.4769\n",
      "Epoch 240/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.0177 - accuracy: 0.6484 - val_loss: 1.3784 - val_accuracy: 0.5026\n",
      "Epoch 241/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0238 - accuracy: 0.6523 - val_loss: 1.3613 - val_accuracy: 0.5077\n",
      "Epoch 242/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0338 - accuracy: 0.6314 - val_loss: 1.3669 - val_accuracy: 0.4667\n",
      "Epoch 243/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0278 - accuracy: 0.6301 - val_loss: 1.3916 - val_accuracy: 0.4718\n",
      "Epoch 244/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.0228 - accuracy: 0.6392 - val_loss: 1.4288 - val_accuracy: 0.4667\n",
      "Epoch 245/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0191 - accuracy: 0.6418 - val_loss: 1.3715 - val_accuracy: 0.4564\n",
      "Epoch 246/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0182 - accuracy: 0.6458 - val_loss: 1.4293 - val_accuracy: 0.4615\n",
      "Epoch 247/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 1.0195 - accuracy: 0.6497 - val_loss: 1.4013 - val_accuracy: 0.4667\n",
      "Epoch 248/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 1.0204 - accuracy: 0.6510 - val_loss: 1.3573 - val_accuracy: 0.4769\n",
      "Epoch 249/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.0139 - accuracy: 0.6536 - val_loss: 1.3886 - val_accuracy: 0.4513\n",
      "Epoch 250/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0166 - accuracy: 0.6418 - val_loss: 1.3566 - val_accuracy: 0.4821\n",
      "Epoch 251/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.0075 - accuracy: 0.6405 - val_loss: 1.3683 - val_accuracy: 0.4769\n",
      "Epoch 252/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0136 - accuracy: 0.6379 - val_loss: 1.3794 - val_accuracy: 0.4718\n",
      "Epoch 253/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 1.0067 - accuracy: 0.6536 - val_loss: 1.4319 - val_accuracy: 0.4462\n",
      "Epoch 254/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 1.0056 - accuracy: 0.6340 - val_loss: 1.5559 - val_accuracy: 0.4359\n",
      "Epoch 255/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0154 - accuracy: 0.6183 - val_loss: 1.3789 - val_accuracy: 0.5077\n",
      "Epoch 256/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0061 - accuracy: 0.6510 - val_loss: 1.4089 - val_accuracy: 0.4564\n",
      "Epoch 257/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 1.0014 - accuracy: 0.6654 - val_loss: 1.3391 - val_accuracy: 0.4872\n",
      "Epoch 258/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 1.0073 - accuracy: 0.6314 - val_loss: 1.4450 - val_accuracy: 0.4308\n",
      "Epoch 259/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9941 - accuracy: 0.6484 - val_loss: 1.4073 - val_accuracy: 0.4615\n",
      "Epoch 260/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.0061 - accuracy: 0.6536 - val_loss: 1.3675 - val_accuracy: 0.5128\n",
      "Epoch 261/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9975 - accuracy: 0.6588 - val_loss: 1.3770 - val_accuracy: 0.4769\n",
      "Epoch 262/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9966 - accuracy: 0.6562 - val_loss: 1.4233 - val_accuracy: 0.4667\n",
      "Epoch 263/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.9907 - accuracy: 0.6562 - val_loss: 1.4200 - val_accuracy: 0.4359\n",
      "Epoch 264/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.0024 - accuracy: 0.6562 - val_loss: 1.4723 - val_accuracy: 0.4462\n",
      "Epoch 265/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9944 - accuracy: 0.6536 - val_loss: 1.3958 - val_accuracy: 0.4821\n",
      "Epoch 266/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9915 - accuracy: 0.6797 - val_loss: 1.3599 - val_accuracy: 0.4667\n",
      "Epoch 267/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.9934 - accuracy: 0.6549 - val_loss: 1.3802 - val_accuracy: 0.4718\n",
      "Epoch 268/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.9770 - accuracy: 0.6261 - val_loss: 1.4497 - val_accuracy: 0.4513\n",
      "Epoch 269/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9740 - accuracy: 0.6562 - val_loss: 1.3993 - val_accuracy: 0.4564\n",
      "Epoch 270/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9842 - accuracy: 0.6654 - val_loss: 1.3497 - val_accuracy: 0.4821\n",
      "Epoch 271/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9838 - accuracy: 0.6471 - val_loss: 1.3855 - val_accuracy: 0.4821\n",
      "Epoch 272/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.9784 - accuracy: 0.6654 - val_loss: 1.4163 - val_accuracy: 0.4718\n",
      "Epoch 273/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9848 - accuracy: 0.6654 - val_loss: 1.3653 - val_accuracy: 0.5026\n",
      "Epoch 274/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9801 - accuracy: 0.6588 - val_loss: 1.3488 - val_accuracy: 0.4974\n",
      "Epoch 275/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9797 - accuracy: 0.6654 - val_loss: 1.4010 - val_accuracy: 0.4615\n",
      "Epoch 276/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9766 - accuracy: 0.6458 - val_loss: 1.4234 - val_accuracy: 0.4513\n",
      "Epoch 277/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.9773 - accuracy: 0.6601 - val_loss: 1.3842 - val_accuracy: 0.4564\n",
      "Epoch 278/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9696 - accuracy: 0.6549 - val_loss: 1.3870 - val_accuracy: 0.4718\n",
      "Epoch 279/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9706 - accuracy: 0.6641 - val_loss: 1.3717 - val_accuracy: 0.4513\n",
      "Epoch 280/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9649 - accuracy: 0.6641 - val_loss: 1.3459 - val_accuracy: 0.4615\n",
      "Epoch 281/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9668 - accuracy: 0.6641 - val_loss: 1.3847 - val_accuracy: 0.4769\n",
      "Epoch 282/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.9594 - accuracy: 0.6797 - val_loss: 1.3595 - val_accuracy: 0.4974\n",
      "Epoch 283/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9705 - accuracy: 0.6667 - val_loss: 1.3887 - val_accuracy: 0.4615\n",
      "Epoch 284/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9543 - accuracy: 0.6732 - val_loss: 1.3702 - val_accuracy: 0.5077\n",
      "Epoch 285/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9579 - accuracy: 0.6797 - val_loss: 1.4805 - val_accuracy: 0.4359\n",
      "Epoch 286/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9653 - accuracy: 0.6654 - val_loss: 1.4568 - val_accuracy: 0.4769\n",
      "Epoch 287/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.9535 - accuracy: 0.6654 - val_loss: 1.3641 - val_accuracy: 0.4410\n",
      "Epoch 288/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9535 - accuracy: 0.6601 - val_loss: 1.3898 - val_accuracy: 0.4513\n",
      "Epoch 289/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9534 - accuracy: 0.6680 - val_loss: 1.3803 - val_accuracy: 0.4923\n",
      "Epoch 290/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9529 - accuracy: 0.6732 - val_loss: 1.3504 - val_accuracy: 0.5026\n",
      "Epoch 291/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9372 - accuracy: 0.6876 - val_loss: 1.3715 - val_accuracy: 0.4718\n",
      "Epoch 292/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9482 - accuracy: 0.6732 - val_loss: 1.3637 - val_accuracy: 0.5282\n",
      "Epoch 293/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9357 - accuracy: 0.6758 - val_loss: 1.4177 - val_accuracy: 0.4718\n",
      "Epoch 294/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9449 - accuracy: 0.6850 - val_loss: 1.3735 - val_accuracy: 0.4769\n",
      "Epoch 295/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9371 - accuracy: 0.6810 - val_loss: 1.3702 - val_accuracy: 0.4821\n",
      "Epoch 296/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.9461 - accuracy: 0.6719 - val_loss: 1.4681 - val_accuracy: 0.4923\n",
      "Epoch 297/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9337 - accuracy: 0.6680 - val_loss: 1.3561 - val_accuracy: 0.4923\n",
      "Epoch 298/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9381 - accuracy: 0.6745 - val_loss: 1.4095 - val_accuracy: 0.4872\n",
      "Epoch 299/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9341 - accuracy: 0.6758 - val_loss: 1.4181 - val_accuracy: 0.4667\n",
      "Epoch 300/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.9321 - accuracy: 0.6810 - val_loss: 1.4283 - val_accuracy: 0.4923\n",
      "Epoch 301/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9360 - accuracy: 0.6758 - val_loss: 1.3428 - val_accuracy: 0.4769\n",
      "Epoch 302/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9318 - accuracy: 0.6706 - val_loss: 1.3942 - val_accuracy: 0.4615\n",
      "Epoch 303/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9238 - accuracy: 0.6693 - val_loss: 1.3807 - val_accuracy: 0.5128\n",
      "Epoch 304/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 0.9294 - accuracy: 0.6876 - val_loss: 1.3712 - val_accuracy: 0.4974\n",
      "Epoch 305/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9260 - accuracy: 0.6797 - val_loss: 1.4394 - val_accuracy: 0.4769\n",
      "Epoch 306/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9322 - accuracy: 0.6863 - val_loss: 1.3733 - val_accuracy: 0.4872\n",
      "Epoch 307/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9330 - accuracy: 0.6797 - val_loss: 1.3730 - val_accuracy: 0.4718\n",
      "Epoch 308/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9268 - accuracy: 0.6797 - val_loss: 1.3872 - val_accuracy: 0.5026\n",
      "Epoch 309/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9232 - accuracy: 0.6876 - val_loss: 1.4095 - val_accuracy: 0.4513\n",
      "Epoch 310/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.9155 - accuracy: 0.6824 - val_loss: 1.3734 - val_accuracy: 0.5128\n",
      "Epoch 311/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9163 - accuracy: 0.6824 - val_loss: 1.4929 - val_accuracy: 0.4615\n",
      "Epoch 312/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9151 - accuracy: 0.6980 - val_loss: 1.3582 - val_accuracy: 0.4821\n",
      "Epoch 313/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9083 - accuracy: 0.6824 - val_loss: 1.4238 - val_accuracy: 0.4718\n",
      "Epoch 314/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.9135 - accuracy: 0.6758 - val_loss: 1.4143 - val_accuracy: 0.4923\n",
      "Epoch 315/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.9046 - accuracy: 0.6876 - val_loss: 1.4263 - val_accuracy: 0.4769\n",
      "Epoch 316/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.9082 - accuracy: 0.6954 - val_loss: 1.4821 - val_accuracy: 0.4718\n",
      "Epoch 317/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9068 - accuracy: 0.6993 - val_loss: 1.3969 - val_accuracy: 0.4667\n",
      "Epoch 318/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.9070 - accuracy: 0.6915 - val_loss: 1.4836 - val_accuracy: 0.4872\n",
      "Epoch 319/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.9131 - accuracy: 0.6824 - val_loss: 1.4543 - val_accuracy: 0.4564\n",
      "Epoch 320/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8997 - accuracy: 0.6928 - val_loss: 1.3525 - val_accuracy: 0.5128\n",
      "Epoch 321/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8989 - accuracy: 0.6954 - val_loss: 1.4073 - val_accuracy: 0.4769\n",
      "Epoch 322/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8891 - accuracy: 0.6915 - val_loss: 1.4242 - val_accuracy: 0.4615\n",
      "Epoch 323/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.9020 - accuracy: 0.6732 - val_loss: 1.3383 - val_accuracy: 0.4769\n",
      "Epoch 324/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.8963 - accuracy: 0.6863 - val_loss: 1.4130 - val_accuracy: 0.4513\n",
      "Epoch 325/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8960 - accuracy: 0.6967 - val_loss: 1.3856 - val_accuracy: 0.4872\n",
      "Epoch 326/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8798 - accuracy: 0.6915 - val_loss: 1.4206 - val_accuracy: 0.4769\n",
      "Epoch 327/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8853 - accuracy: 0.6850 - val_loss: 1.4308 - val_accuracy: 0.4667\n",
      "Epoch 328/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.8882 - accuracy: 0.7033 - val_loss: 1.4329 - val_accuracy: 0.4667\n",
      "Epoch 329/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.8926 - accuracy: 0.6902 - val_loss: 1.3782 - val_accuracy: 0.4821\n",
      "Epoch 330/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8737 - accuracy: 0.7020 - val_loss: 1.4033 - val_accuracy: 0.4821\n",
      "Epoch 331/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8772 - accuracy: 0.7046 - val_loss: 1.3806 - val_accuracy: 0.4821\n",
      "Epoch 332/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8821 - accuracy: 0.6824 - val_loss: 1.4252 - val_accuracy: 0.4718\n",
      "Epoch 333/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.8765 - accuracy: 0.6954 - val_loss: 1.3525 - val_accuracy: 0.4821\n",
      "Epoch 334/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8856 - accuracy: 0.7059 - val_loss: 1.4335 - val_accuracy: 0.4513\n",
      "Epoch 335/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8749 - accuracy: 0.7020 - val_loss: 1.4143 - val_accuracy: 0.4667\n",
      "Epoch 336/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8793 - accuracy: 0.7033 - val_loss: 1.3788 - val_accuracy: 0.4667\n",
      "Epoch 337/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8700 - accuracy: 0.7150 - val_loss: 1.3818 - val_accuracy: 0.4615\n",
      "Epoch 338/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.8756 - accuracy: 0.7072 - val_loss: 1.4072 - val_accuracy: 0.4821\n",
      "Epoch 339/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8706 - accuracy: 0.6928 - val_loss: 1.3961 - val_accuracy: 0.4974\n",
      "Epoch 340/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.8692 - accuracy: 0.7098 - val_loss: 1.3719 - val_accuracy: 0.5077\n",
      "Epoch 341/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.8710 - accuracy: 0.7190 - val_loss: 1.4675 - val_accuracy: 0.4564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.8733 - accuracy: 0.7176 - val_loss: 1.3652 - val_accuracy: 0.4974\n",
      "Epoch 343/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8615 - accuracy: 0.7229 - val_loss: 1.4059 - val_accuracy: 0.4769\n",
      "Epoch 344/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8501 - accuracy: 0.6941 - val_loss: 1.4781 - val_accuracy: 0.4615\n",
      "Epoch 345/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8601 - accuracy: 0.7098 - val_loss: 1.4236 - val_accuracy: 0.4410\n",
      "Epoch 346/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.8604 - accuracy: 0.7046 - val_loss: 1.4029 - val_accuracy: 0.4974\n",
      "Epoch 347/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.8694 - accuracy: 0.7033 - val_loss: 1.3697 - val_accuracy: 0.4974\n",
      "Epoch 348/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.8543 - accuracy: 0.7033 - val_loss: 1.4472 - val_accuracy: 0.4769\n",
      "Epoch 349/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8507 - accuracy: 0.7085 - val_loss: 1.3636 - val_accuracy: 0.4615\n",
      "Epoch 350/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.8514 - accuracy: 0.7150 - val_loss: 1.4224 - val_accuracy: 0.4718\n",
      "Epoch 351/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.8544 - accuracy: 0.7098 - val_loss: 1.4009 - val_accuracy: 0.4615 \n",
      "Epoch 352/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.8552 - accuracy: 0.6993 - val_loss: 1.4620 - val_accuracy: 0.4462\n",
      "Epoch 353/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8551 - accuracy: 0.7242 - val_loss: 1.3814 - val_accuracy: 0.5026\n",
      "Epoch 354/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8397 - accuracy: 0.7176 - val_loss: 1.4073 - val_accuracy: 0.4821\n",
      "Epoch 355/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.8481 - accuracy: 0.7111 - val_loss: 1.3963 - val_accuracy: 0.4872\n",
      "Epoch 356/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8539 - accuracy: 0.7190 - val_loss: 1.4853 - val_accuracy: 0.4513\n",
      "Epoch 357/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8392 - accuracy: 0.7190 - val_loss: 1.4520 - val_accuracy: 0.4615\n",
      "Epoch 358/500\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 0.8345 - accuracy: 0.7150 - val_loss: 1.3787 - val_accuracy: 0.4974\n",
      "Epoch 359/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8419 - accuracy: 0.7124 - val_loss: 1.3709 - val_accuracy: 0.5077\n",
      "Epoch 360/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.8388 - accuracy: 0.7229 - val_loss: 1.4718 - val_accuracy: 0.4615\n",
      "Epoch 361/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.8319 - accuracy: 0.7190 - val_loss: 1.4100 - val_accuracy: 0.4872\n",
      "Epoch 362/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8347 - accuracy: 0.7046 - val_loss: 1.4921 - val_accuracy: 0.4410\n",
      "Epoch 363/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.8287 - accuracy: 0.7150 - val_loss: 1.5281 - val_accuracy: 0.4256\n",
      "Epoch 364/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8348 - accuracy: 0.7072 - val_loss: 1.3711 - val_accuracy: 0.4667\n",
      "Epoch 365/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.8259 - accuracy: 0.7229 - val_loss: 1.3601 - val_accuracy: 0.5026\n",
      "Epoch 366/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.8329 - accuracy: 0.7176 - val_loss: 1.3947 - val_accuracy: 0.4769\n",
      "Epoch 367/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.8223 - accuracy: 0.7150 - val_loss: 1.3889 - val_accuracy: 0.4821\n",
      "Epoch 368/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8177 - accuracy: 0.7333 - val_loss: 1.4235 - val_accuracy: 0.4872\n",
      "Epoch 369/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.8162 - accuracy: 0.7255 - val_loss: 1.3968 - val_accuracy: 0.4974\n",
      "Epoch 370/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8199 - accuracy: 0.7229 - val_loss: 1.3831 - val_accuracy: 0.4974\n",
      "Epoch 371/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.8234 - accuracy: 0.7176 - val_loss: 1.3636 - val_accuracy: 0.4667\n",
      "Epoch 372/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8214 - accuracy: 0.7124 - val_loss: 1.3593 - val_accuracy: 0.4872\n",
      "Epoch 373/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.8218 - accuracy: 0.7203 - val_loss: 1.4039 - val_accuracy: 0.4821\n",
      "Epoch 374/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8051 - accuracy: 0.7229 - val_loss: 1.5171 - val_accuracy: 0.4513\n",
      "Epoch 375/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.8129 - accuracy: 0.7307 - val_loss: 1.3986 - val_accuracy: 0.4872\n",
      "Epoch 376/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.8056 - accuracy: 0.7333 - val_loss: 1.3587 - val_accuracy: 0.4974\n",
      "Epoch 377/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8087 - accuracy: 0.7320 - val_loss: 1.3687 - val_accuracy: 0.4923\n",
      "Epoch 378/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.8138 - accuracy: 0.7242 - val_loss: 1.3789 - val_accuracy: 0.5282\n",
      "Epoch 379/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8091 - accuracy: 0.7281 - val_loss: 1.3632 - val_accuracy: 0.4718\n",
      "Epoch 380/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.8039 - accuracy: 0.7307 - val_loss: 1.4112 - val_accuracy: 0.4718\n",
      "Epoch 381/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.7991 - accuracy: 0.7386 - val_loss: 1.4397 - val_accuracy: 0.4923\n",
      "Epoch 382/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.8034 - accuracy: 0.7216 - val_loss: 1.3597 - val_accuracy: 0.4974\n",
      "Epoch 383/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.8044 - accuracy: 0.7216 - val_loss: 1.3777 - val_accuracy: 0.4513\n",
      "Epoch 384/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7930 - accuracy: 0.7412 - val_loss: 1.4209 - val_accuracy: 0.4872\n",
      "Epoch 385/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.7950 - accuracy: 0.7412 - val_loss: 1.4006 - val_accuracy: 0.4821\n",
      "Epoch 386/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.7940 - accuracy: 0.7320 - val_loss: 1.4106 - val_accuracy: 0.4872\n",
      "Epoch 387/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7968 - accuracy: 0.7281 - val_loss: 1.3944 - val_accuracy: 0.5077\n",
      "Epoch 388/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7930 - accuracy: 0.7281 - val_loss: 1.4155 - val_accuracy: 0.4821\n",
      "Epoch 389/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7908 - accuracy: 0.7281 - val_loss: 1.3318 - val_accuracy: 0.4718\n",
      "Epoch 390/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.7834 - accuracy: 0.7412 - val_loss: 1.3839 - val_accuracy: 0.4769\n",
      "Epoch 391/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7908 - accuracy: 0.7477 - val_loss: 1.3724 - val_accuracy: 0.5179\n",
      "Epoch 392/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.7856 - accuracy: 0.7425 - val_loss: 1.3520 - val_accuracy: 0.4821\n",
      "Epoch 393/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7920 - accuracy: 0.7386 - val_loss: 1.4061 - val_accuracy: 0.4769\n",
      "Epoch 394/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7842 - accuracy: 0.7529 - val_loss: 1.4712 - val_accuracy: 0.4615\n",
      "Epoch 395/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7855 - accuracy: 0.7281 - val_loss: 1.4181 - val_accuracy: 0.4821\n",
      "Epoch 396/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.7870 - accuracy: 0.7386 - val_loss: 1.3885 - val_accuracy: 0.5128\n",
      "Epoch 397/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.7678 - accuracy: 0.7425 - val_loss: 1.4653 - val_accuracy: 0.4564\n",
      "Epoch 398/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7735 - accuracy: 0.7373 - val_loss: 1.3508 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.7772 - accuracy: 0.7451 - val_loss: 1.4400 - val_accuracy: 0.4923\n",
      "Epoch 400/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7769 - accuracy: 0.7281 - val_loss: 1.3992 - val_accuracy: 0.5077\n",
      "Epoch 401/500\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.7660 - accuracy: 0.7320 - val_loss: 1.3920 - val_accuracy: 0.4974\n",
      "Epoch 402/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7651 - accuracy: 0.7412 - val_loss: 1.4268 - val_accuracy: 0.4769\n",
      "Epoch 403/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7682 - accuracy: 0.7503 - val_loss: 1.4124 - val_accuracy: 0.4769\n",
      "Epoch 404/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7753 - accuracy: 0.7438 - val_loss: 1.4086 - val_accuracy: 0.5077\n",
      "Epoch 405/500\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.7639 - accuracy: 0.7412 - val_loss: 1.4203 - val_accuracy: 0.4974\n",
      "Epoch 406/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.7633 - accuracy: 0.7490 - val_loss: 1.4617 - val_accuracy: 0.4821\n",
      "Epoch 407/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.7607 - accuracy: 0.7399 - val_loss: 1.4714 - val_accuracy: 0.4667\n",
      "Epoch 408/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.7646 - accuracy: 0.7412 - val_loss: 1.3772 - val_accuracy: 0.5026\n",
      "Epoch 409/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.7584 - accuracy: 0.7373 - val_loss: 1.3920 - val_accuracy: 0.4615\n",
      "Epoch 410/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.7570 - accuracy: 0.7621 - val_loss: 1.4855 - val_accuracy: 0.4615\n",
      "Epoch 411/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.7540 - accuracy: 0.7503 - val_loss: 1.3888 - val_accuracy: 0.5333\n",
      "Epoch 412/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7479 - accuracy: 0.7569 - val_loss: 1.3539 - val_accuracy: 0.4923\n",
      "Epoch 413/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.7600 - accuracy: 0.7464 - val_loss: 1.3944 - val_accuracy: 0.4923\n",
      "Epoch 414/500\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.7485 - accuracy: 0.7542 - val_loss: 1.3571 - val_accuracy: 0.4769\n",
      "Epoch 415/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.7472 - accuracy: 0.7621 - val_loss: 1.3484 - val_accuracy: 0.4974\n",
      "Epoch 416/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.7444 - accuracy: 0.7673 - val_loss: 1.3632 - val_accuracy: 0.4718\n",
      "Epoch 417/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7513 - accuracy: 0.7464 - val_loss: 1.4309 - val_accuracy: 0.4667\n",
      "Epoch 418/500\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.7388 - accuracy: 0.7569 - val_loss: 1.4178 - val_accuracy: 0.4564\n",
      "Epoch 419/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.7455 - accuracy: 0.7673 - val_loss: 1.4151 - val_accuracy: 0.4821\n",
      "Epoch 420/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.7375 - accuracy: 0.7542 - val_loss: 1.4529 - val_accuracy: 0.5026\n",
      "Epoch 421/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7332 - accuracy: 0.7529 - val_loss: 1.4950 - val_accuracy: 0.4513\n",
      "Epoch 422/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7302 - accuracy: 0.7621 - val_loss: 1.3519 - val_accuracy: 0.4974\n",
      "Epoch 423/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7351 - accuracy: 0.7647 - val_loss: 1.3755 - val_accuracy: 0.4872\n",
      "Epoch 424/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7274 - accuracy: 0.7582 - val_loss: 1.4255 - val_accuracy: 0.4923\n",
      "Epoch 425/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.7287 - accuracy: 0.7621 - val_loss: 1.3572 - val_accuracy: 0.4769\n",
      "Epoch 426/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.7421 - accuracy: 0.7438 - val_loss: 1.4056 - val_accuracy: 0.4923\n",
      "Epoch 427/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.7237 - accuracy: 0.7464 - val_loss: 1.4334 - val_accuracy: 0.4872\n",
      "Epoch 428/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7294 - accuracy: 0.7503 - val_loss: 1.3844 - val_accuracy: 0.4923\n",
      "Epoch 429/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7194 - accuracy: 0.7608 - val_loss: 1.3724 - val_accuracy: 0.5128\n",
      "Epoch 430/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7278 - accuracy: 0.7595 - val_loss: 1.3722 - val_accuracy: 0.4974\n",
      "Epoch 431/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7199 - accuracy: 0.7595 - val_loss: 1.4524 - val_accuracy: 0.4667\n",
      "Epoch 432/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.7215 - accuracy: 0.7569 - val_loss: 1.4080 - val_accuracy: 0.4821\n",
      "Epoch 433/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7221 - accuracy: 0.7477 - val_loss: 1.4070 - val_accuracy: 0.4872\n",
      "Epoch 434/500\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.7186 - accuracy: 0.7725 - val_loss: 1.4084 - val_accuracy: 0.4872\n",
      "Epoch 435/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.7201 - accuracy: 0.7686 - val_loss: 1.3761 - val_accuracy: 0.4974\n",
      "Epoch 436/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.6996 - accuracy: 0.7595 - val_loss: 1.4578 - val_accuracy: 0.4769\n",
      "Epoch 437/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7092 - accuracy: 0.7556 - val_loss: 1.4690 - val_accuracy: 0.4821\n",
      "Epoch 438/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7036 - accuracy: 0.7791 - val_loss: 1.3646 - val_accuracy: 0.4872\n",
      "Epoch 439/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7131 - accuracy: 0.7778 - val_loss: 1.4272 - val_accuracy: 0.4821\n",
      "Epoch 440/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7039 - accuracy: 0.7699 - val_loss: 1.4471 - val_accuracy: 0.4821\n",
      "Epoch 441/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6952 - accuracy: 0.7712 - val_loss: 1.3807 - val_accuracy: 0.4872\n",
      "Epoch 442/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.7010 - accuracy: 0.7725 - val_loss: 1.4183 - val_accuracy: 0.4718\n",
      "Epoch 443/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.7050 - accuracy: 0.7477 - val_loss: 1.4068 - val_accuracy: 0.4821\n",
      "Epoch 444/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.7071 - accuracy: 0.7556 - val_loss: 1.4379 - val_accuracy: 0.4718\n",
      "Epoch 445/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6977 - accuracy: 0.7595 - val_loss: 1.3866 - val_accuracy: 0.4821\n",
      "Epoch 446/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6994 - accuracy: 0.7725 - val_loss: 1.4197 - val_accuracy: 0.5026\n",
      "Epoch 447/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6973 - accuracy: 0.7699 - val_loss: 1.4414 - val_accuracy: 0.4872\n",
      "Epoch 448/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6953 - accuracy: 0.7725 - val_loss: 1.3996 - val_accuracy: 0.4821\n",
      "Epoch 449/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.6918 - accuracy: 0.7739 - val_loss: 1.4126 - val_accuracy: 0.4923\n",
      "Epoch 450/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6844 - accuracy: 0.7712 - val_loss: 1.3906 - val_accuracy: 0.4821\n",
      "Epoch 451/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.6870 - accuracy: 0.7765 - val_loss: 1.3815 - val_accuracy: 0.4872\n",
      "Epoch 452/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6957 - accuracy: 0.7699 - val_loss: 1.4059 - val_accuracy: 0.4872\n",
      "Epoch 453/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6837 - accuracy: 0.7712 - val_loss: 1.4259 - val_accuracy: 0.4974\n",
      "Epoch 454/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6809 - accuracy: 0.7856 - val_loss: 1.4667 - val_accuracy: 0.4718\n",
      "Epoch 455/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6914 - accuracy: 0.7765 - val_loss: 1.4185 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.6780 - accuracy: 0.7791 - val_loss: 1.4145 - val_accuracy: 0.4974\n",
      "Epoch 457/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6735 - accuracy: 0.7817 - val_loss: 1.4642 - val_accuracy: 0.4667\n",
      "Epoch 458/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6770 - accuracy: 0.7843 - val_loss: 1.4081 - val_accuracy: 0.4821\n",
      "Epoch 459/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6803 - accuracy: 0.7699 - val_loss: 1.3716 - val_accuracy: 0.5179\n",
      "Epoch 460/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6763 - accuracy: 0.7830 - val_loss: 1.4202 - val_accuracy: 0.4615\n",
      "Epoch 461/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.6777 - accuracy: 0.7804 - val_loss: 1.4272 - val_accuracy: 0.4872\n",
      "Epoch 462/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6714 - accuracy: 0.7895 - val_loss: 1.3865 - val_accuracy: 0.5179\n",
      "Epoch 463/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6714 - accuracy: 0.7752 - val_loss: 1.4428 - val_accuracy: 0.4974\n",
      "Epoch 464/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6637 - accuracy: 0.7895 - val_loss: 1.4201 - val_accuracy: 0.5077\n",
      "Epoch 465/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6662 - accuracy: 0.7765 - val_loss: 1.4691 - val_accuracy: 0.4769\n",
      "Epoch 466/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.6601 - accuracy: 0.7882 - val_loss: 1.3936 - val_accuracy: 0.4974\n",
      "Epoch 467/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6653 - accuracy: 0.7725 - val_loss: 1.3716 - val_accuracy: 0.4769\n",
      "Epoch 468/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6656 - accuracy: 0.7882 - val_loss: 1.4263 - val_accuracy: 0.4974\n",
      "Epoch 469/500\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.6642 - accuracy: 0.7895 - val_loss: 1.4921 - val_accuracy: 0.4667\n",
      "Epoch 470/500\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.6548 - accuracy: 0.7882 - val_loss: 1.3835 - val_accuracy: 0.4974\n",
      "Epoch 471/500\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.6576 - accuracy: 0.7948 - val_loss: 1.4360 - val_accuracy: 0.4872\n",
      "Epoch 472/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6615 - accuracy: 0.7765 - val_loss: 1.5075 - val_accuracy: 0.4821\n",
      "Epoch 473/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6565 - accuracy: 0.7895 - val_loss: 1.4418 - val_accuracy: 0.4821\n",
      "Epoch 474/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6401 - accuracy: 0.7908 - val_loss: 1.4132 - val_accuracy: 0.5077\n",
      "Epoch 475/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6461 - accuracy: 0.7922 - val_loss: 1.4154 - val_accuracy: 0.4872\n",
      "Epoch 476/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.6476 - accuracy: 0.7882 - val_loss: 1.4338 - val_accuracy: 0.4718\n",
      "Epoch 477/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6528 - accuracy: 0.7895 - val_loss: 1.4519 - val_accuracy: 0.4872\n",
      "Epoch 478/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6448 - accuracy: 0.7935 - val_loss: 1.5113 - val_accuracy: 0.4667\n",
      "Epoch 479/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6392 - accuracy: 0.7895 - val_loss: 1.4426 - val_accuracy: 0.5026\n",
      "Epoch 480/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.6367 - accuracy: 0.8000 - val_loss: 1.4308 - val_accuracy: 0.5077\n",
      "Epoch 481/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6387 - accuracy: 0.8052 - val_loss: 1.4005 - val_accuracy: 0.4821\n",
      "Epoch 482/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6420 - accuracy: 0.7935 - val_loss: 1.4182 - val_accuracy: 0.4974\n",
      "Epoch 483/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6378 - accuracy: 0.7987 - val_loss: 1.4803 - val_accuracy: 0.4667\n",
      "Epoch 484/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6350 - accuracy: 0.7974 - val_loss: 1.4508 - val_accuracy: 0.4821\n",
      "Epoch 485/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6349 - accuracy: 0.7922 - val_loss: 1.4651 - val_accuracy: 0.4974\n",
      "Epoch 486/500\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.6331 - accuracy: 0.8065 - val_loss: 1.4162 - val_accuracy: 0.4923\n",
      "Epoch 487/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6302 - accuracy: 0.8026 - val_loss: 1.4260 - val_accuracy: 0.4923\n",
      "Epoch 488/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.6244 - accuracy: 0.8013 - val_loss: 1.4230 - val_accuracy: 0.4923\n",
      "Epoch 489/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6257 - accuracy: 0.8105 - val_loss: 1.4270 - val_accuracy: 0.4667\n",
      "Epoch 490/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6133 - accuracy: 0.8157 - val_loss: 1.4554 - val_accuracy: 0.4821\n",
      "Epoch 491/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6246 - accuracy: 0.7987 - val_loss: 1.4723 - val_accuracy: 0.4872\n",
      "Epoch 492/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6164 - accuracy: 0.8026 - val_loss: 1.4319 - val_accuracy: 0.4769\n",
      "Epoch 493/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 1.4197 - val_accuracy: 0.4769\n",
      "Epoch 494/500\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.6127 - accuracy: 0.7895 - val_loss: 1.3934 - val_accuracy: 0.4974\n",
      "Epoch 495/500\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.6141 - accuracy: 0.8118 - val_loss: 1.3664 - val_accuracy: 0.4974\n",
      "Epoch 496/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6049 - accuracy: 0.8065 - val_loss: 1.5162 - val_accuracy: 0.4462\n",
      "Epoch 497/500\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.6178 - accuracy: 0.8092 - val_loss: 1.3996 - val_accuracy: 0.4923\n",
      "Epoch 498/500\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.5987 - accuracy: 0.8157 - val_loss: 1.4325 - val_accuracy: 0.4821\n",
      "Epoch 499/500\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6055 - accuracy: 0.8065 - val_loss: 1.4784 - val_accuracy: 0.4564\n",
      "Epoch 500/500\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6015 - accuracy: 0.8105 - val_loss: 1.5682 - val_accuracy: 0.4718\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\kesar\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 47.18%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17352456, 0.25994307, 0.1309728 , ..., 0.01024791, 0.01319168,\n",
       "        0.01559422],\n",
       "       [0.05339563, 0.17030816, 0.18664989, ..., 0.04408742, 0.04959857,\n",
       "        0.08632009],\n",
       "       [0.04260015, 0.15701845, 0.01894369, ..., 0.05471371, 0.16142567,\n",
       "        0.11298004],\n",
       "       ...,\n",
       "       [0.01141318, 0.02975521, 0.02214918, ..., 0.22104071, 0.24566199,\n",
       "        0.19757834],\n",
       "       [0.09836877, 0.16359848, 0.1776575 , ..., 0.02479063, 0.01952628,\n",
       "        0.03052839],\n",
       "       [0.11480284, 0.19656353, 0.13807884, ..., 0.00867137, 0.02779337,\n",
       "        0.03068423]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 6, 0, 1, 3, 1, 4, 1, 1, 6, 2, 1, 4, 7, 9, 4, 7, 4, 9, 1, 7,\n",
       "       6, 9, 1, 0, 6, 7, 1, 1, 9, 3, 6, 2, 3, 7, 0, 9, 0, 6, 4, 3, 1, 4,\n",
       "       0, 2, 5, 1, 1, 3, 6, 1, 6, 0, 1, 9, 5, 1, 8, 6, 5, 0, 4, 1, 9, 7,\n",
       "       1, 3, 1, 1, 6, 9, 2, 1, 9, 3, 3, 7, 1, 4, 4, 1, 5, 4, 7, 4, 2, 0,\n",
       "       8, 1, 1, 1, 3, 3, 0, 1, 9, 4, 1, 0, 1, 0, 1, 6, 0, 1, 3, 3, 7, 6,\n",
       "       9, 1, 1, 6, 1, 9, 1, 1, 2, 1, 2, 6, 1, 3, 5, 1, 1, 4, 4, 4, 5, 3,\n",
       "       1, 5, 8, 9, 5, 7, 2, 5, 6, 3, 2, 0, 9, 4, 6, 1, 5, 4, 7, 7, 8, 3,\n",
       "       6, 7, 5, 4, 7, 1, 8, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0     female_calm\n",
       "1  female_fearful\n",
       "2       male_calm\n",
       "3    female_angry\n",
       "4     female_calm\n",
       "5    female_happy\n",
       "6     female_calm\n",
       "7      female_sad\n",
       "8     female_calm\n",
       "9     female_calm"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualvalues\n",
       "0  female_angry\n",
       "1  female_happy\n",
       "2  female_angry\n",
       "3      male_sad\n",
       "4   female_calm\n",
       "5      male_sad\n",
       "6    female_sad\n",
       "7  female_angry\n",
       "8   female_calm\n",
       "9      male_sad"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues predictedvalues\n",
       "0      female_angry     female_calm\n",
       "1      female_happy  female_fearful\n",
       "2      female_angry       male_calm\n",
       "3          male_sad    female_angry\n",
       "4       female_calm     female_calm\n",
       "..              ...             ...\n",
       "158    male_fearful    male_fearful\n",
       "159    female_happy     female_calm\n",
       "160    male_fearful      male_happy\n",
       "161  female_fearful    female_happy\n",
       "162        male_sad     female_calm\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predictedvalues\n",
       "actualvalues                   \n",
       "female_angry                 12\n",
       "female_calm                  17\n",
       "female_fearful               24\n",
       "female_happy                 14\n",
       "female_sad                   16\n",
       "male_angry                   11\n",
       "male_calm                    13\n",
       "male_fearful                 15\n",
       "male_happy                   19\n",
       "male_sad                     22"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "female_angry               13\n",
       "female_calm                44\n",
       "female_fearful             10\n",
       "female_happy               17\n",
       "female_sad                 18\n",
       "male_angry                 11\n",
       "male_calm                  17\n",
       "male_fearful               14\n",
       "male_happy                  5\n",
       "male_sad                   14"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
